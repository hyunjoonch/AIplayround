# -*- coding: utf-8 -*-
"""해양침적쓰레기분류 Using CNN (baseline).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e_xUIBxcTmYMDccJEiRjO4axUrNzB3OQ

## Marine Garbage Detection (해양쓰레기분류)
### https://aihub.or.kr/problem_contest/nipa-learning-platform/10
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn import preprocessing

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import load_model
from keras.utils.vis_utils import plot_model
from tensorflow.keras.constraints import MaxNorm

import pickle, PIL, io, os
import zipfile
from os.path import exists
from tqdm import tqdm

from tensorflow.keras.datasets import mnist
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
DATA_DIR = "/content/drive/MyDrive/AI허브/bc"

PROJECT = '해양쓰레기분류'

"""#### Load train images"""

TRAIN_ZIP_FILE = os.path.join(DATA_DIR, PROJECT, PROJECT + '_train.zip')
TEST_ZIP_FILE = os.path.join(DATA_DIR, PROJECT, PROJECT + '_test.zip')

IMAGE_SIZE = 150

def load_images(where, files):
    images = None
    with zipfile.ZipFile(where) as thezip:
        for _, im in tqdm(enumerate(files)):
            image = PIL.Image.open(io.BytesIO(thezip.read(os.path.join("images", im)))) \
                .convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))  # Convert to grayscale and resize
            image = np.expand_dims(np.array(image, dtype=int), axis=0)
            images = image if images is None else np.append(images, image, axis=0)
    return images

with zipfile.ZipFile(TRAIN_ZIP_FILE) as thezip:
    with thezip.open('train.csv', mode='r') as thefile:
        train = pd.read_csv(thefile)

train

le = preprocessing.LabelEncoder()
le.fit(train.category)
le.classes_

train_labels = np.array(le.transform(train.category))
train_labels

le.inverse_transform(train_labels)

TRAIN_IMAGES_FILE = os.path.join(DATA_DIR, PROJECT, PROJECT + "_train_images.pkl")

if exists(TRAIN_IMAGES_FILE):
    with open(TRAIN_IMAGES_FILE, 'rb') as f:
        train_images = pickle.load(f)
else:
    train_images = load_images(TRAIN_ZIP_FILE, train.file_name)
    with open(TRAIN_IMAGES_FILE, 'wb') as f:
        pickle.dump(train_images, f, pickle.HIGHEST_PROTOCOL)

train_images.shape

"""#### Build a Model and Train it"""

keras_model = Sequential()
keras_model.add(Conv2D(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1), kernel_size=(3, 3),kernel_constraint=MaxNorm(3), padding="same", filters=32))
keras_model.add(MaxPooling2D((4, 4), strides=2))
keras_model.add(Conv2D(kernel_size=(3, 3), padding="same", filters=32))
keras_model.add(MaxPooling2D((4, 4), strides=2))

keras_model.add(Conv2D(kernel_size=(3, 3), padding="same", filters=32))
keras_model.add(MaxPooling2D((4, 4), strides=2))
keras_model.add(Conv2D(kernel_size=(3, 3), padding="same", filters=32))
keras_model.add(MaxPooling2D((4, 4), strides=2))





keras_model.add(Flatten())
keras_model.add(Dense(256,activation="relu", kernel_constraint=MaxNorm(3)))
keras_model.add(Dense(20, activation="softmax"))
# keras_model.summary()

keras_model.compile(
    optimizer="adam",
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

plot_model(keras_model, show_shapes=True, show_layer_activations=True)

seed = 8
np.random.seed(seed)

X_train, X_valid, y_train, y_valid = train_test_split(train_images, train_labels, test_size=0.3,random_state=seed, shuffle=True, stratify=train_labels)
X_train.shape, X_valid.shape

X_train = np.array(X_train) / 255
X_valid = np.array(X_valid) / 255

y_train = np.array(y_train)
y_valid = np.array(y_valid)

X_train = X_train.astype('float32')
X_valid = X_valid.astype('float32')

"""#### 과적합을 방지하고 데이터집합의 불균형을 처리하기 위한 데이터 보강"""

datagen = ImageDataGenerator(
    featurewise_center=False,              # 데이터셋에 대해 입력 평균을 0으로 설정
    samplewise_center=False,               # 각 샘플 평균을 0으로 설정
    featurewise_std_normalization=False,   # 데이터 세트의 표준으로 입력 나눕니다.
    samplewise_std_normalization=False,    # 각 입력을 std로 나눕니다.
    width_shift_range=0.15,                 # 이미지를 가로로 무작위로 이동(전체 너비의 일부)
    height_shift_range=0.15

)

datagen.fit(X_train)

datagen = ImageDataGenerator(featurewise_center=True,
                             featurewise_std_normalization=True,
                             zca_whitening=True)

import tensorflow as tf

mobile_model = tf.keras.applications.MobileNetV2(
    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),
    include_top=False, # Remove classification head
    weights='imagenet')

for layer in mobile_model.layers:
    layer.trainable = False

model = tf.keras.Sequential(
    [mobile_model,
     GlobalAveragePooling2D(),
     Dropout(0.3),
     Flatten(),
     Dense(1024, activation='relu', kernel_constraint=MaxNorm(3)),
     Dropout(0.3),
     Dense(512, activation='relu', kernel_constraint=MaxNorm(3)),
     Dropout(0.3),
     Dense(20, activation='softmax')])


model.compile(optimizer="adam", loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1,factor=0.3, min_lr=0.000001)

model.fit(
    datagen.flow(X_train, y_train, batch_size=36),
    epochs=120,
    validation_data=datagen.flow(X_valid, y_valid),
    callbacks = [early_stopping, learning_rate_reduction]
)

print("Accuracy:", model.evaluate(X_valid, y_valid)[1])

y_pred = le.inverse_transform(np.array([np.argmax(pred) for pred in model.predict(X_valid)]))
y_test = le.inverse_transform(y_valid)

print(classification_report(y_test, y_pred))

def compare_and_visualize(X_test, y_test, y_pred):
    y_test = le.inverse_transform(y_test)
    y_pred = le.inverse_transform(y_pred)
    plt.figure(figsize=(12,16))
    for i in range(30):
        plt.subplot(6,5,i+1)
        plt.imshow(X_test[i].reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray', interpolation='none')
        plt.title("Label:{}\n Pred:{}".format(y_test[i], y_pred[i]))
        plt.axis('off')

submission_df = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))

TEST_IMAGES_FILE = os.path.join(DATA_DIR, PROJECT, PROJECT + "_test_images.pkl")

if exists(TEST_IMAGES_FILE):
    with open(TEST_IMAGES_FILE, 'rb') as f:
        test_images = pickle.load(f)
else:
    test_images = load_images(TEST_ZIP_FILE, submission_df.file_name)
    with open(TEST_IMAGES_FILE, 'wb') as f:
        pickle.dump(test_images, f, pickle.HIGHEST_PROTOCOL)

submission_images = np.array(test_images) / 255

submission_pred = le.inverse_transform(np.array([np.argmax(pred) for pred in model.predict(submission_images)]))

submission_df.category = submission_pred
submission_df.head()

submission_df.to_csv(os.path.join(DATA_DIR, 'submission.csv'), index=False)

